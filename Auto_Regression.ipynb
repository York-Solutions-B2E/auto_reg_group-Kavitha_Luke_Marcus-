{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import libraries for data visualization\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import libraries for building linear regression model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Import library for preparing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import library for data preprocessing\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Import libraries for scoring models\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. import, X-y separation, train_test_split\n",
    "#### 2. EDA\n",
    "#### 3. create 6 datasets\n",
    "#### 4. impute, encoding, separate cat/num\n",
    "#### 5. build models\n",
    "#### 6. score models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"auto_1993_adj.csv\")\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will drop \"ID\" as it is unlikely to contribute to our analysis\n",
    "df = df.drop(\"ID\", axis=1)\n",
    "features = df.drop(\"mpg\", axis=1)\n",
    "target = df[\"mpg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.hist(bins=25, figsize = (12,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_matrix = df.corr()\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(corr_matrix, annot=True, cmap=\"YlOrRd\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(data=df, corner=True, height=3)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>displacement</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>mpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307.0</td>\n",
       "      <td>8</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   displacement  cylinders  horsepower  weight  acceleration  model_year  \\\n",
       "0         307.0          8       130.0    3504          12.0          70   \n",
       "\n",
       "   origin   mpg  \n",
       "0       1  18.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.copy()\n",
    "X = X.dropna(axis=0)\n",
    "y = X.pop(\"mpg\")\n",
    "\n",
    "# All discrete features should now have integer dtypes (double-check this before using MI!)\n",
    "discrete_features = X.dtypes == int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  displacement  cylinders  horsepower  weight  acceleration  model_year  \\\n",
      "0   1         307.0          8       130.0    3504          12.0          70   \n",
      "1   2         350.0          8       165.0    3693          11.5          70   \n",
      "2   3         318.0          8       150.0    3436          11.0          70   \n",
      "3   4         304.0          8       150.0    3433          12.0          70   \n",
      "4   5         302.0          8       140.0    3449          10.5          70   \n",
      "\n",
      "   origin  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n",
      "(392,)\n",
      "ID               True\n",
      "displacement    False\n",
      "cylinders        True\n",
      "horsepower      False\n",
      "weight           True\n",
      "acceleration    False\n",
      "model_year       True\n",
      "origin           True\n",
      "dtype: bool\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     mi_scores \u001b[38;5;241m=\u001b[39m mi_scores\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mi_scores\n\u001b[0;32m---> 11\u001b[0m mi_scores \u001b[38;5;241m=\u001b[39m \u001b[43mmake_mi_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m mi_scores[::\u001b[38;5;241m3\u001b[39m]  \u001b[38;5;66;03m# show a few features with their MI scores\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m, in \u001b[0;36mmake_mi_scores\u001b[0;34m(X, y, discrete_features)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(discrete_features)\n\u001b[0;32m----> 6\u001b[0m mi_scores \u001b[38;5;241m=\u001b[39m \u001b[43mmutual_info_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscrete_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m mi_scores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(mi_scores, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMI Scores\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m      8\u001b[0m mi_scores \u001b[38;5;241m=\u001b[39m mi_scores\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_selection/_mutual_info.py:399\u001b[0m, in \u001b[0;36mmutual_info_regression\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    313\u001b[0m     {\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     X, y, \u001b[38;5;241m*\u001b[39m, discrete_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    325\u001b[0m ):\n\u001b[1;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Estimate mutual information for a continuous target variable.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m    Mutual information (MI) [1]_ between two random variables is a non-negative\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m           of a Random Vector\", Probl. Peredachi Inf., 23:2 (1987), 9-16\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_estimate_mi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_selection/_mutual_info.py:305\u001b[0m, in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    297\u001b[0m     y \u001b[38;5;241m=\u001b[39m scale(y, with_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    298\u001b[0m     y \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m         \u001b[38;5;241m1e-10\u001b[39m\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(\u001b[38;5;241m1\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(y)))\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;241m*\u001b[39m rng\u001b[38;5;241m.\u001b[39mstandard_normal(size\u001b[38;5;241m=\u001b[39mn_samples)\n\u001b[1;32m    302\u001b[0m     )\n\u001b[1;32m    304\u001b[0m mi \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 305\u001b[0m     \u001b[43m_compute_mi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, discrete_feature \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(_iterate_columns(X), discrete_mask)\n\u001b[1;32m    307\u001b[0m ]\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(mi)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_selection/_mutual_info.py:164\u001b[0m, in \u001b[0;36m_compute_mi\u001b[0;34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mutual_info_score(x, y)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x_discrete \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y_discrete:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compute_mi_cd\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x_discrete \u001b[38;5;129;01mand\u001b[39;00m y_discrete:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compute_mi_cd(x, y, n_neighbors)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_selection/_mutual_info.py:141\u001b[0m, in \u001b[0;36m_compute_mi_cd\u001b[0;34m(c, d, n_neighbors)\u001b[0m\n\u001b[1;32m    138\u001b[0m c \u001b[38;5;241m=\u001b[39m c[mask]\n\u001b[1;32m    139\u001b[0m radius \u001b[38;5;241m=\u001b[39m radius[mask]\n\u001b[0;32m--> 141\u001b[0m kd \u001b[38;5;241m=\u001b[39m \u001b[43mKDTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m m_all \u001b[38;5;241m=\u001b[39m kd\u001b[38;5;241m.\u001b[39mquery_radius(c, radius, count_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    143\u001b[0m m_all \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(m_all)\n",
      "File \u001b[0;32msklearn/neighbors/_binary_tree.pxi:826\u001b[0m, in \u001b[0;36msklearn.neighbors._kd_tree.BinaryTree.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:967\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 967\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    969\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    970\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    971\u001b[0m         )\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    974\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "def make_mi_scores(X, y, discrete_features):\n",
    "    print(X.head())\n",
    "    print(y.shape)\n",
    "    print(discrete_features)\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "mi_scores = make_mi_scores(X, y, discrete_features)\n",
    "mi_scores[::3]  # show a few features with their MI scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 Distinct Feature Sets\n",
    "# # Set 1\n",
    "df1 = features\n",
    "df2 = features[[\"displacement\", \"horsepower\"]]\n",
    "df3 = df[[\"cylinders\"]]\n",
    "df4 = df[[\"model_year\"]]\n",
    "# df5 = df[[\"displacement\", \"horsepower\"]]\n",
    "# df6 = df[[\"displacement\", \"horsepower\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_regres(data, model):\n",
    "    # Separate features and target\n",
    "    X = data\n",
    "    global target\n",
    "    y = target\n",
    "    # train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=16\n",
    "    )\n",
    "\n",
    "    # Separate CAT & NUM features\n",
    "    cat_cols = [\"cylinders\", \"origin\"]\n",
    "    num_cols = [\"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model_year\"]\n",
    "    cat_cols = [col for col in data.columns if col in cat_cols]\n",
    "    num_cols = [col for col in data.columns if col in num_cols]\n",
    "\n",
    "    # Transform NUM Data\n",
    "    numerical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer()),\n",
    "            (\"scale\", StandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Transform CAT Data\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "    # Create Data Preprocessor Process\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numerical_transformer, num_cols),\n",
    "            (\"cat\", categorical_transformer, cat_cols),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # # Define models\n",
    "    # knn = KNeighborsRegressor()\n",
    "    # svr = SVR()\n",
    "    # ridge = Ridge()\n",
    "\n",
    "    # Preprocess data then create model\n",
    "    mod_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "    # Preprocess training data, fit model\n",
    "    mod_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Get predictions for training data\n",
    "    preds = mod_pipeline.predict(X_train)\n",
    "\n",
    "    print(\" MAE:\", mean_squared_error(y_train, preds))\n",
    "    print(\"R_2:\", r2_score(y_train, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "knn = KNeighborsRegressor()\n",
    "svr = SVR()\n",
    "ridge = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_regres(df4, ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cv_regres(data, model):\n",
    "#     # Separate features and target\n",
    "#     X = data.drop(\"mpg\", axis=1)\n",
    "#     y = data[\"mpg\"]\n",
    "\n",
    "#     # train test split\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=0.25, random_state=16\n",
    "#     )\n",
    "\n",
    "#     # Separate CAT & NUM features\n",
    "#     cat_cols = [\"cylinders\", \"origin\"]\n",
    "#     num_cols = [\"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model_year\"]\n",
    "#     cat_cols = [col for col in data.columns if col in cat_cols]\n",
    "#     num_cols = [col for col in data.columns if col in num_cols]\n",
    "\n",
    "#     # Transform NUM Data\n",
    "#     numerical_transformer = Pipeline(\n",
    "#         steps=[\n",
    "#             (\"imputer\", SimpleImputer()),\n",
    "#             (\"scale\", StandardScaler()),\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     # Transform CAT Data\n",
    "#     categorical_transformer = Pipeline(\n",
    "#         steps=[\n",
    "#             (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "#             (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "#         ]\n",
    "#     )\n",
    "#     # Create Data Preprocessor Process\n",
    "#     preprocessor = ColumnTransformer(\n",
    "#         transformers=[\n",
    "#             (\"num\", numerical_transformer, num_cols),\n",
    "#             (\"cat\", categorical_transformer, cat_cols),\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     # Define models\n",
    "#     knn = KNeighborsRegressor()\n",
    "#     svr = SVR()\n",
    "#     ridge = Ridge()\n",
    "\n",
    "#     # Preprocess data then create model\n",
    "#     mod_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "#     # Cross-Validation Code\n",
    "#     scores = -1 * cross_val_score(\n",
    "#         mod_pipeline, X, y, cv=5, scoring=\"neg_mean_absolute_error\"\n",
    "#     )\n",
    "\n",
    "#     print(\"MAE scores:\\n\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_regres(df1,ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple_imputer = SimpleImputer()\n",
    "# X_train_imputed = pd.DataFrame(simple_imputer.fit_transform(X_train))\n",
    "# X_test_imputed = pd.DataFrame(simple_imputer.transform(X_test))\n",
    "# X_train_imputed.columns = X_train.columns\n",
    "# X_test_imputed.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer()),\n",
    "        (\"scale\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply ordinal encoder to each column with categorical data\n",
    "# ordinal_encoder = OrdinalEncoder()\n",
    "# label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])\n",
    "# label_X_valid[object_cols] = ordinal_encoder.transform(X_valid[object_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # One Hot Encoder\n",
    "# # Apply one-hot encoder to each column with categorical data\n",
    "# OHE = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "# OH_cols_train = pd.DataFrame(OHE.fit_transform(X_train_imputed[cat_cols]))\n",
    "# OH_cols_valid = pd.DataFrame(OHE.transform(X_test_imputed[cat_cols]))\n",
    "\n",
    "# # One-hot encoding removed index; put it back\n",
    "# OH_cols_train.index = X_train_imputed.index\n",
    "# OH_cols_valid.index = X_test_imputed.index\n",
    "\n",
    "# # Remove categorical columns (will replace with one-hot encoding)\n",
    "# num_X_train_imputed = X_train_imputed.drop(cat_cols, axis=1)\n",
    "# num_X_test_imputed = X_test_imputed.drop(cat_cols, axis=1)\n",
    "\n",
    "# # Add one-hot encoded columns to numerical features\n",
    "# OH_X_train_imputed = pd.concat([num_X_train_imputed, OH_cols_train], axis=1)\n",
    "# OH_X_test_imputed = pd.concat([num_X_test_imputed, OH_cols_valid], axis=1)\n",
    "\n",
    "# # Ensure all columns have string type\n",
    "# OH_X_train_imputed.columns = OH_X_train_imputed.columns.astype(str)\n",
    "# OH_X_test_imputed.columns = OH_X_test_imputed.columns.astype(str)\n",
    "\n",
    "# # print(\"MAE from Approach 3 (One-Hot Encoding):\")\n",
    "# # print(score_dataset(OH_X_train_imputed, OH_X_test_imputed, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OH_X_train_imputed.head(15)\n",
    "# OH_X_train_imputed.rename(\n",
    "#     columns={\n",
    "#         \"0\": \"cyl_3\",\n",
    "#         \"1\": \"cyl_4\",\n",
    "#         \"2\": \"cyl_5\",\n",
    "#         \"3\": \"cyl_6\",\n",
    "#         \"4\": \"cyl_8\",\n",
    "#         \"5\": \"org_1\",\n",
    "#         \"6\": \"org_2\",\n",
    "#         \"7\": \"org_3\"},\n",
    "#     inplace=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "knn = KNeighborsRegressor()\n",
    "svr = SVR()\n",
    "ridge = Ridge()\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", knn)])\n",
    "\n",
    "# Preprocessing of training data, fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = clf.predict(X_train)\n",
    "\n",
    "# score = mean_absolute_error(y_valid, preds)\n",
    "print(\" MAE:\", mean_squared_error(y_train, preds))\n",
    "print(\"R_2:\", r2_score(y_train, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
